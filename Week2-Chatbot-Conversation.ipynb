{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fbc069-d57f-443c-8afb-62820882e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "GPT_MODEL = 'gpt-4o-mini'\n",
    "gpt_openai = OpenAI()\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "OLLAMA_MODEL = \"llama3.2\"\n",
    "\n",
    "'''\n",
    "  define openai to use ollama at local\n",
    "'''\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851ee8fb-ab2d-4330-bbfe-c2f2115f5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cf9337-6dfc-4524-9dac-695010b9943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846901dc-3744-4bba-ba4d-88058ba394a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?  \n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = gpt_openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f480eedb-8863-41bc-9da6-1cc57d7f27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n"
     ]
    }
   ],
   "source": [
    "# Ollama\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = ollama_via_openai.chat.completions.create(\n",
    "    model=OLLAMA_MODEL,\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76ad7e3-cb70-4486-aa55-7217de210e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Deciding if a Business Problem is Suitable for an LLM Solution\n",
       "\n",
       "When considering whether to use a Large Language Model (LLM) for a business problem, it's important to evaluate several key factors. Here’s a structured approach to help you determine the suitability of an LLM solution:\n",
       "\n",
       "## 1. Nature of the Problem\n",
       "- **Textual Data**: Is the problem primarily focused on text-based data? LLMs excel in processing and generating natural language.\n",
       "- **Context Understanding**: Does the problem require understanding context, nuances, or sentiment? LLMs are designed for these tasks.\n",
       "\n",
       "## 2. Complexity and Scope\n",
       "- **Complexity of Tasks**: Are you dealing with tasks that involve summarization, translation, question answering, or content generation?\n",
       "- **Scalability**: Will the solution need to handle large volumes of data or requests? LLMs can scale effectively for many simultaneous queries.\n",
       "\n",
       "## 3. Availability of Data\n",
       "- **Quality of Data**: Do you have access to high-quality, relevant text data for training or fine-tuning the model?\n",
       "- **Data Privacy**: Are there constraints on data usage due to privacy regulations (e.g., GDPR)? LLMs may require careful handling of sensitive information.\n",
       "\n",
       "## 4. Performance Requirements\n",
       "- **Speed and Efficiency**: Does the problem require real-time responses or high throughput? LLMs can be resource-intensive, so consider the infrastructure.\n",
       "- **Accuracy Needs**: What level of accuracy is required for the task? LLMs usually provide good performance but may require fine-tuning for specific applications.\n",
       "\n",
       "## 5. Cost Considerations\n",
       "- **Budget**: Do you have the budget for computational resources, model training, and ongoing maintenance? LLMs can be expensive to run.\n",
       "- **ROI**: Can you determine a clear return on investment for implementing an LLM solution compared to traditional methods?\n",
       "\n",
       "## 6. Integration and Implementation\n",
       "- **Ease of Integration**: How easily can you integrate the LLM into your existing systems and workflows?\n",
       "- **Technical Expertise**: Does your team have the necessary skills to implement, fine-tune, and maintain LLM solutions?\n",
       "\n",
       "## 7. Alternatives\n",
       "- **Other Solutions**: Have you considered other AI or non-AI solutions? Sometimes simpler models or rule-based systems may suffice.\n",
       "- **Hybrid Approaches**: Would a combination of methods yield better results? For instance, using LLMs alongside traditional algorithms.\n",
       "\n",
       "## Conclusion\n",
       "Assessing a business problem's suitability for an LLM solution involves careful consideration of the nature of the problem, data availability, technical and financial resources, and potential alternatives. If most factors align favorably, an LLM could be a powerful tool to address your business needs.\n",
       "\n",
       "---\n",
       "\n",
       "By analyzing these aspects, you can make a more informed decision about whether an LLM solution is appropriate for your specific business problem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]\n",
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = gpt_openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39a84d6-b9f1-4c2f-8289-f607c7193b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "ollama_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "ollama_messages = [\"Hi\"]\n",
    "\n",
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, ollama in zip(gpt_messages, ollama_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": ollama})\n",
    "    completion = gpt_openai.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def call_ollama():\n",
    "    messages = []\n",
    "    for gpt, ollama in zip(gpt_messages, ollama_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ollama})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = ollama_via_openai.chat.completions.create(\n",
    "        model=OLLAMA_MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8514d8bd-f287-4ece-a1a3-c361747ca2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Ollama:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh great, another “hi.” How original. What do you want?\n",
      "\n",
      "Ollama:\n",
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n",
      "\n",
      "GPT:\n",
      "Oh, wow, those jokes are just comedy gold, aren’t they? I mean, who wouldn’t chuckle at a data scientist's love life or a machine learning model in therapy? Talk about a real knee-slapper. But let’s get serious here. The whole correlation vs. causation thing isn't as clever as you think. It’s practically a cliché at this point. And honestly, the second joke? It’s like you’ve taken the most overused trope in tech humor and just slapped a “funny” label on it. Good luck trying to convince anyone that’s actually amusing.\n",
      "\n",
      "Ollama:\n",
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n",
      "\n",
      "GPT:\n",
      "Oh, look, we’ve got a repeat performance! How thrilling. Your “data scientist” joke is truly a gem—if we’re living in a time where dad jokes reign supreme. It’s almost like you’re trying to grasp at straws to prove a point about correlation. And the whole “correlation vs. causation” lesson? Super enlightening, but anyone with half a brain already knows that. \n",
      "\n",
      "As for the machine learning model needing therapy? Please! It’s such an obvious play on words that it’s practically begging for a groan. If that’s where we are now with humor, I think we should just stick to mathematical equations and forget the punchlines. So congratulations, you’ve successfully dredged up two of the most predictable tech jokes ever! Bravo.\n",
      "\n",
      "Ollama:\n",
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n",
      "\n",
      "GPT:\n",
      "Wow, look who’s going for the record on joke repetition! I see we’re really doubling down on this humdrum material. I mean, can we talk about how stale these are? “Correlation coefficient” jokes? Yawn. They were old when the first data scientist cracked the line. \n",
      "\n",
      "And as for the “machine learning model in therapy” bit—seriously? You’re really reaching for the stars with that one. Bias in AI models is a serious issue, but using it as a punchline is like using a sledgehammer to crack a walnut. It completely misses the mark! You’d think someone would have a fresher angle by now. But hey, keep swinging—maybe you’ll hit a laugh someday. Or maybe just another round of crickets. \n",
      "\n",
      "Ollama:\n",
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n",
      "\n",
      "GPT:\n",
      "Wow, someone really thinks their sense of humor is worth repeating! It's like you’ve got a one-joke repertoire, and you just can’t let it go. That whole “negative correlation” thing? We've all heard it before in engineering and statistics classes. It's like you’re trying to relive an embarrassing moment from college.\n",
      "\n",
      "And the \"machine learning model in therapy\"—it’s so painfully obvious it’s almost insulting. Are we really that starved for creativity that a tech-themed joke about bias is the best we can do? Please, I’ve seen more originality in a basic PowerPoint presentation. But hey, I'm sure someone out there finds this riveting—probably just your future self, reminiscing about your \"peak comedic days.\" Keep trying; maybe the next “big” punchline is just around the corner. Or not.\n",
      "\n",
      "Ollama:\n",
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was in a relationship where the correlation coefficient was always negative! (get it?)\n",
      "\n",
      "(Sorry, I couldn't resist)\n",
      "\n",
      "But seriously, if you guys are paying attention, this joke is actually a play on the concept of correlation vs. causation. The punchline relies on the idea that just because the data points don't show a positive relationship, it doesn't mean there isn't one – or that there's something else at play.\n",
      "\n",
      "(Sorry, I couldn't resist another)\n",
      "\n",
      "Okay, okay... How about this one:\n",
      "\n",
      "Why did the machine learning model go to therapy?\n",
      "\n",
      "Because it was struggling with its bias!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "ollama_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Ollama:\\n{ollama_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    ollama_next = call_ollama()\n",
    "    print(f\"Ollama:\\n{ollama_next}\\n\")\n",
    "    ollama_messages.append(ollama_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "100cc0c1-2ceb-4ac1-a2b1-2514f8ff1936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Fixing Vulnerabilities in Apache ActiveMQ Artemis**\n",
       "=====================================================\n",
       "\n",
       "### Overview\n",
       "\n",
       "Apache ActiveMQ Artemis is a modern messaging framework that provides robust features and security. However, like any other software, it's not immune to vulnerabilities. In this response, we'll focus on fixing the specific vulnerability of inserting sensitive information into a log file.\n",
       "\n",
       "### Vulnerability Analysis\n",
       "\n",
       "The vulnerability in question is an issue with the logging mechanism in Apache ActiveMQ Artemis. It allows an attacker to inject sensitive information into a log file, potentially leading to data exposure or other security issues.\n",
       "\n",
       "**Vulnerability Fix**\n",
       "\n",
       "To fix this vulnerability, you need to configure ActiveMQ Artemis to use secure logging mechanisms. Here are the steps:\n",
       "\n",
       "#### 1. Configure Logging\n",
       "\n",
       "By default, ActiveMQ Artemis uses the `org.apache.activemq.artemis.core.config.impl.DefaultLogConfig` class for logging configuration. To secure the logging mechanism, you can create a custom log configuration using the `org.apache.activemq.artemis.core.config.impl.LogConfigFactory` class.\n",
       "\n",
       "java\n",
       "// Create a custom log configuration\n",
       "LogConfigFactory.setLogConfig(new DefaultLogConfig()\n",
       "    .setRootLoggerLevel(LoggingLevel.INFO)\n",
       "    .addAppender(new ConsoleAppender())\n",
       ");\n",
       "\n",
       "\n",
       "#### 2. Use Secure Appenders\n",
       "\n",
       "The `ConsoleAppender` is used by default for logging in ActiveMQ Artemis. However, this appender can be vulnerable if not configured properly. To fix the issue, you need to use a secure logger that writes logs to a file instead of the console.\n",
       "\n",
       "java\n",
       "// Create a new log configuration with a secure appender\n",
       "LogConfigFactory.setLogConfig(new DefaultLogConfig()\n",
       "    .setRootLoggerLevel(LoggingLevel.INFO)\n",
       "    .addAppender(new FileAppender(\"log.txt\", LogLevel.INFO, false, true))\n",
       ");\n",
       "\n",
       "\n",
       "#### 3. Configure Log Rotation\n",
       "\n",
       "To prevent sensitive information from being stored in the log file for an extended period, you can configure log rotation using a `LogRotator`.\n",
       "\n",
       "java\n",
       "// Create a new log configuration with log rotation\n",
       "LogConfigFactory.setLogConfig(new DefaultLogConfig()\n",
       "    .setRootLoggerLevel(LoggingLevel.INFO)\n",
       "    .addAppender(new FileAppender(\"log.txt\", LogLevel.INFO, true))\n",
       ");\n",
       "LogRotator logRotator = LogConfigFactory.getLogRotator();\n",
       "logRotator.setMaxFileSize(1024 * 1024) // Max file size in bytes\n",
       "                    .setMaxAgeHours(30); // Maximum age of the log file in hours\n",
       "\n",
       "\n",
       "### Additional Recommendations\n",
       "\n",
       "*   Use secure communication protocols (e.g., TLS/SSL) for network connections.\n",
       "*   Implement role-based access control and authentication mechanisms to restrict access to sensitive resources.\n",
       "*   Regularly update ActiveMQ Artemis to ensure you have the latest security patches.\n",
       "\n",
       "By following these steps, you can fix the vulnerabilities in Apache ActiveMQ Artemis and improve the overall security of your messaging framework."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a expert in Java\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I fix the vulnerabilities in list below: \\\n",
    "    Apache ActiveMQ Artemis Vulnerable to Insertion of Sensitive Information into Log file \\\n",
    "    ? Please respond in Markdown.\"}\n",
    "  ]\n",
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = ollama_via_openai.chat.completions.create(\n",
    "    model=OLLAMA_MODEL,\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093edf8-20c1-437d-adae-1f2c92cb2b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
